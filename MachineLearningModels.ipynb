{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning (ML) Models \n",
    "\n",
    "* ML = automated detection of patterns in data\n",
    "  * (if we could detect those patterns ourselves, we wound't need ML!\n",
    "\n",
    "\n",
    "## Types of ML\n",
    "\n",
    "* There are a bewildering array of ML algorithms out there!\n",
    "  * Although simple ones often perform quite well\n",
    "* most ML algorithms fall into three broad categories:\n",
    " - **Predictive algorithms**: analyze current and historical facts to make predictions about the future, such as\n",
    "   * what will customer enjoy watching\n",
    "   * \"people who bought this also bought that\"\n",
    "   * how much will your home sell for?\n",
    " - **Classification algorithms**: learn from a body of labeled data (e.g., cancer scans), then use that knowledge to classify new observations\n",
    "   * (isn't this what a medical resident does?)\n",
    " - **Time-series forecasting algorithms**: specialized type of predictive algorithms, hence a separate category.   \n",
    "   * beyond the scope of this course, but we have more than enough work with focusing here on prediction and classification\n",
    "\n",
    "## Prediction: linear regression\n",
    "\n",
    "> **Learning goal:** familiarity with fitting linear regression models, and interpreting their output\n",
    "\n",
    "* Arguably the simplest form of ML is to draw a line connecting two points and make predictions about where that trend might lead\n",
    "\n",
    "> But what if you have more than two points—and those points don't line up neatly? What if you have points in more than two dimensions? This is where linear regression comes in.\n",
    "\n",
    "* Process: predict a quantitative *response* (the values on a Y axis) that is dependent on one or more *predictors* (values on one or more axes that are orthogonal to Y, commonly just thought of collectively as X)\n",
    "  * working assumption is that the relationship between predictors and response is more or less linear\n",
    "  * Goal: fit a straight line in the best possible way to minimize the deviation between our observed responses in the dataset and the responses predicted by our line, the linear approximation\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"Images/linear_regression2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Statistically, we can represent this relationship between response and predictors as:\n",
    "\n",
    "$Y = B_0 + B_1X + E$\n",
    "\n",
    "> Remember your geometry? $B_0$ is the intercept of our line and $B_1$ is its slope. We commonly refer to $B_0$ and $B_1$ as coefficients and to $E$ as the *error term*, which represents the margin of error in the model.\n",
    "\n",
    "### Data exploration\n",
    "\n",
    "* We'll begin by importing the libraries we'll need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # \"Pandas\"\n",
    "import numpy as np # \"Numerical Python\"\n",
    "import matplotlib.pyplot as plt # A plotting package\n",
    "import seaborn as sns # Another plotting package\n",
    "%matplotlib inline\n",
    "# the above is a directive to Jupyter to ensure plots appear immediately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* now read in the data\n",
    "* in this case, we’ll use a newer housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Housing_Dataset_Sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you remember the DataFrame method for looking at overall information\n",
    "# about a DataFrame, such as number of columns and rows? Try it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's also use the `describe` method to look at some statistics about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in cases like this, where the column names are long, it can be helpful to view the transposition of the summary, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* let's look at the data in the **Price** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Price']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As we would hope with this much data, our prices form a nice bell-shaped, normally distributed curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* let's look at a simple relationship like that between house prices and the average income in a geographic area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(df['Avg. Area Income'],df['Price']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there is an intuitive, linear relationship between them\n",
    "* Also good: the pairplot shows the data in both columns is normally distributed, so we don't have to worry about somehow transforming the data for meaningful analysis\n",
    "* let's take a quick look at all of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some observations:\n",
    "1. Not all combinations of columns provide strong linear relationships–some just look like blobs\n",
    "  * That's nothing to worry about for our analysis\n",
    "2. The visualizations that look like lines rather than groups...that's the result of the average number of bedrooms in houses being measured in discrete values rather than continuous ones\n",
    "\n",
    "> It is now time to make a prediction!\n",
    "\n",
    "### Fitting the model\n",
    "\n",
    "* We feed everything into a linear model (average area income, average area house age, average area number of rooms, average area number of bedrooms, and area population) and see how well these factors can help us predict the price of a home\n",
    "\n",
    "> To do this, we will make our first five columns the X (our predictors) and the **Price** column the Y (our response):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :5]\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We don't want to use ALL of our data!\n",
    "\n",
    "> Data Scientists divide their datasets into *training* data (the data used to fit or _create_ the model) and *test* data (data used to evaluate how accurate the model is)\n",
    "* scikit-learn provides a function to do this for us–__`train_test_split`__\n",
    "  * we'll use 70 percent of our data for training and reserve 30 percent of it for testing\n",
    "  * note that you will also supply a fourth parameter __`random_state`__\n",
    "    * __`train_test_split`__ randomly divides up our data between test and training, so this number provides an explicit seed for the random-number generator so that you will get the same result each time you run this code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All that is left now is to import our linear regression algorithm and fit our model based on our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Now, a moment of truth: let's see how our model does making predictions based on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* our predictions are the house prices that our model predicts, one for every row in our test dataset.\n",
    "\n",
    "> Remember how we mentioned that linear models have the mathematical form of $Y = B_0 + B_1*X + E$? Let’s look at the actual equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'intercept = {reg.intercept_:,.2f}')\n",
    "for coef in reg.coef_:\n",
    "    print(f'{coef:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In algebraic terms, here is our model:\n",
    "\n",
    "$Y=-2,646,401+21.59X_1+165,828.19X_2+121,323.5X_3+2,790X_4+15.17X_5$\n",
    "\n",
    "where:\n",
    " - $Y=$ Price\n",
    " - $X_1=$ Average area income\n",
    " - $X_2=$ Average area house age\n",
    " - $X_3=$ Average area number of rooms\n",
    " - $X_4=$ Average area number of bedrooms\n",
    " - $X_5=$ Area population\n",
    "\n",
    "> So, just how good is our model?\n",
    " * There are many ways to measure the accuracy of ML models (and details are beyond the scope here)\n",
    "   * Linear models have a good one: the $R^2$ score (also knows as the coefficient of determination)\n",
    "   * A high $R^2$, close to 1, indicates better prediction with less error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variation. A high R2 close to 1 indicates better prediction with less error.\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The $R^2$ score also indicates how much explanatory power a linear model has. In the case of our model, the five predictors we used in the model explain a little more than 92% of the price of a house in this dataset.\n",
    "\n",
    "* We can also plot our errors to get a visual sense of how wrong our predictions were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot errors\n",
    "sns.distplot([y_test - predictions]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice the numbers on the left axis\n",
    " * whereas a histogram shows the number of things that fall into discrete numeric buckets, a kernel density estimation (KDE, and the histogram that accompanies it in the Seaborn displot) normalizes those numbers to show what proportion of results lands in each bucket\n",
    " * essentially, these are all numbers less than 1.0 because the area under the KDE has to add up to 1\n",
    "\n",
    "> Maybe more gratifying, we can plot the predictions from our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(y_test, predictions, color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you think of a way to refine this visualization to make it clearer, particularly if you were explaining the results to someone?\n",
    "\n",
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Remember to try the plt.scatter parameter alpha=.\n",
    "# It takes values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Takeaway:** In this subsection, you performed prediction using linear regression by exploring your data, then fitting your model, and finally evaluating your model’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Logistic Regression\n",
    "\n",
    "> **Learning goal:** understand how logistic regression differs from linear regression, be comfortable fitting logistic regression models, and have some familiarity with interpreting their output\n",
    "\n",
    "* Let's pivot to discussing classification\n",
    "  * If our simple analogy of predictive analytics was drawing a line through points and extrapolating from that, then classification can be described in its simplest form as drawing lines around groups of points\n",
    "\n",
    "* While linear regression is used to predict quantitative responses (or continuous numeric values, such as home prices), *logistic* regression is used for classification problems\n",
    "  * in this algorithm, the probabilities describing the possible outcomes of a single trial are modeled using a sigmoid (S-curve) function]\n",
    "  * sigmoid functions take any value and transform it to be between 0 and 1, which can be used as a probability for a class to be predicted, with the goal of predictors mapping to 1 when something belongs in the class and 0 when they do not.\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"Images/logistic_regression.png?\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> to demonstrate, let's do something a little different and try a historical dataset–the fates of the passengers of the RMS Titanic, which is a popular dataset for classification problems in machine learning\n",
    "  * the class we want to predict is whether a passenger survived \n",
    "\n",
    "The dataset has 12 variables:\n",
    "\n",
    " - **PassengerId**\n",
    " - **Survived:** 0 = No, 1 = Yes\n",
    " - **Pclass:** Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    " - **Sex**\n",
    " - **Age**\t\t\n",
    " - **Sibsp:** Number of siblings or spouses aboard the *Titanic*\t\n",
    " - **Parch:** Number of parents or children aboard the *Titanic*\n",
    " - **Ticket:** Passenger ticket number\t\n",
    " - **Fare:** Passenger fare\t\n",
    " - **Cabin:** Cabin number\t\n",
    " - **Embarked:** Port of embarkation; C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/train_data_titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One reason that the Titanic data set is a popular classification set is that it provides opportunities to prepare data for analysis\n",
    " * To prepare this dataset for analysis, we need to perform a number of tasks:\n",
    "  - Remove extraneous variables\n",
    "  - Check for multicollinearity \n",
    "  - Handle missing values\n",
    "\n",
    "### Remove extraneous variables\n",
    "\n",
    "* names of passengers and their ticket numbers clearly won't help our model, so we can drop those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Name', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there may be additional variables that won't add classifying power to our model\n",
    "  * to find them we will need to look for correlation between variables\n",
    "\n",
    "### Check for multicollinearity\n",
    "\n",
    "> If one or more of our predictors can themselves be predicted from other predictors, it can produce a state of *multicollinearity* in our model\n",
    "  * basically, we are exaggerating the effect of a variable by include it \"twice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seaborn has a nice function called __`heatmap`__ which will we can use on the correlations between pairs of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we can see a high correlation between Fare and Pclass...why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop Fare as a result\n",
    "df.drop(['Fare'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values\n",
    "\n",
    "* we now need to address missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We could try to do something about those missing values\n",
    " * However, if any pattern does emerge in the data that involves **Cabin**, it will be highly correlated with both **Pclass** and **Fare**\n",
    " * And the vast majority of those values are missing, so it could be difficult to reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's now run `info` to see if there are columns with just a few null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: given that 1,503 died in the *Titanic* tragedy (and that we know that some survived), this data set clearly does not include every passenger on the ship (and none of the crew)\n",
    "\n",
    "* back to missing values\n",
    "  * **Age** is missing several values, as is **Embarked**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].isnull().value_counts() # another way to look at the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As we saw above, **Age** isn't really correlated with **Fare**, so it is a variable that we want to eventually use in our model\n",
    " * that means that we need to do something with those missing values\n",
    "   * we could just fill in the missing ones with some known value, such as the mean or median\n",
    "   * ...let's check to see if our median age is the same for both sexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Sex')['Age'].median().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or a better way...\n",
    "df.groupby(['Sex'])['Age'].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The median ages are different for men and women sailing on the *Titanic*, so we should handle the missing values accordingly\n",
    "* a sound strategy is to replace the missing ages for passengers with the median age, based on sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df.groupby('Sex')['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Any other missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We are missing two values for **Embarked**. Check to see how that variable breaks down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the vast majority of passengers embarked on the *Titanic* from Southampton, so we will just fill in those two missing values with the most statistically likely value (the median result): Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].fillna(df['Embarked'].value_counts().idxmax(), inplace=True)\n",
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we need to turn the categorical values ('Sex' and 'Embarked') into numbers so we can perform ML on the data\n",
    " * numerical equivalents of categorical variables are called \"dummy variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Sex', 'Embarked'],drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a final look at the correlation matrix to see if there is anything else we should remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: we need to remove **Survived** from our X DataFrame because it will be our response DataFrame, Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we import and fit the logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear') # avoid deprecation warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "In contrast to linear regression, logistic regression does not produce an $R^2$ score by which we can assess the accuracy of our model. In order to evaluate that, we will use a classification report, a confusion matrix, and the accuracy score.\n",
    "\n",
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The classification reports the proportions of both survivors and non-survivors with four scores, but for simplicity, we'll think of them in terms of document retrieval (Google Search)\n",
    " - **Precision:** the percentage of responses that are valid given the query\n",
    " - **Recall:** the percentage of documents we were supposed to return that we actually did return\n",
    " - **F1 score:** The harmonic mean (a kind of average) of precision and recall.\n",
    " - **Support:** The number of true instances for each label.\n",
    " \n",
    "* Why so many ways of measuring accuracy for a model?\n",
    "  * Well, success means different things in different contexts\n",
    "  * Imagine that we had a model to diagnose cancer\n",
    "   * such as system should maximize _recall_, that is we want to be sure and identify every person with cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "> a confusion matrix is another way to present this same information, this time with raw scores\n",
    " * columns show the true condition, positive on the left, negative on the right\n",
    " * rows show predicted conditions, positive on the top, negative on the bottom\n",
    " * matrix below shows that our model correctly predicted 146 survivors (true positives) and incorrectly predicted another 16 (false positives)\n",
    " * on the other hand, our model correctly predicted 30 non-survivors (true negatives) and incorrectly predicted 76 more (false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* let's dress up the confusion matrix a bit to make it a little easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, predictions), columns=['True Survived', 'True Not Survived'], index=['Predicted Survived', 'Predicted Not Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy score\n",
    "\n",
    "* finally, our accuracy score tells us the fraction of correctly classified samples; in this case (146 + 76) / (146 + 76 + 30 + 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not bad for an off-the-shelf model with no tuning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: decision trees\n",
    "\n",
    "> **Learning goal:** By the end of this subsection, you should be comfortable fitting decision-tree models and have some understanding of what they output.\n",
    "\n",
    "If logistic regression uses observations about variables to swing a metaphorical needle between 0 and 1, classification based on decision trees programmatically builds a Yes/No decision to classify items.\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"Images/decision_tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's look at this in practice with the same *Titanic* dataset we used with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tree.DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same split data as with the logistic regression,\n",
    "# can you fit the decision tree model?\n",
    "# Hint: Refer to code snippet for fitting the logistic regression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Once fitted, we get our predicitions just like we did in the logistic regression example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_predictions = tr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, tr_predictions), \n",
    "             columns=['True Survived', 'True Not Survived'], \n",
    "             index=['Predicted Survived', 'Predicted Not Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,tr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One of the great attractions of decision trees is that the models are readable by humans. Let's visualize to see it in action. (Note, the generated graphic can be quite large, so scroll to the right if the generated graphic just looks blank at first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_file = export_graphviz(tr, out_file='titanic.dot', \n",
    "                                feature_names=X.columns, \n",
    "                                class_names=['Perished', 'Survived'],\n",
    "                                filled=True, rounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng titanic.dot -o titanic.png\n",
    "from IPython.display import Image\n",
    "Image('titanic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> **Takeaway:** In this subsection, you performed classification on previously cleaned data by fitting and evaluating a decision tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
